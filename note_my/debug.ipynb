{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! load_ext autoreload\n",
    "! autoreload 2\n",
    "from diffusers import StableDiffusionPipeline, EulerAncestralDiscreteScheduler\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "from itertools import groupby\n",
    "from typing import Callable, Dict, List, Optional, Set, Tuple, Type, Union\n",
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from lora_diffusion import LoraInjectedConv2d, LoraInjectedLinear, patch_pipe, tune_lora_scale\n",
    "from lora_diffusion.lora import _find_modules, UNET_CROSSATTN_TARGET_REPLACE\n",
    "from reg_lora.visual import visualize_images\n",
    "\n",
    "os.environ[\"DISABLE_TELEMETRY\"] = 'YES'\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "device = torch.device(\"cuda:3\")\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16,local_files_only=True,revision='39593d5650112b4cc580433f6b0435385882d819').to(device)\n",
    "pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "prompt = \"style of <s1><s2>, baby lion\"\n",
    "torch.manual_seed(0)\n",
    "# image = pipe(prompt, num_inference_steps=50, guidance_scale=7).images[0]\n",
    "\n",
    "# image  # nice. diffusers are cool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reg_lora.clip_reg import CLIPTiDataset, CLIPTiScoreCalculator\n",
    "from lora_diffusion.lora import patch_pipe\n",
    "lora_ckpt = '../outputs/checkpoints/output_dog_Ti-clip_Nonorm_3e-5/lora_weight_e6_s1000.safetensors'\n",
    "torch.manual_seed(0)\n",
    "\n",
    "patch_pipe(\n",
    "    pipe,\n",
    "    lora_ckpt,\n",
    "    patch_text=False,\n",
    "    patch_ti=True,\n",
    "    patch_unet=True,\n",
    "    filter_crossattn_str = 'cross+self'\n",
    ")\n",
    "\n",
    "data  = CLIPTiDataset(instance_data_root=\"../custom_data/data/dog\",\n",
    "                      placeholder_tokens=\"<krk1>\",\n",
    "                      class_token='dog'\n",
    "                      )\n",
    "clip = CLIPTiScoreCalculator(text_model = pipe.text_encoder.text_model,\n",
    "                             tokenizer = pipe.tokenizer,\n",
    "                             placeholder_tokens = \"<krk1>\",\n",
    "                             class_token_len = 1)\n",
    "data_loader = torch.utils.data.DataLoader(data, batch_size=2, shuffle=False, num_workers=1)\n",
    "clip_batch = next(iter(data_loader))\n",
    "instance_texts = clip_batch['text']\n",
    "instance_images = [image for image in clip_batch['np_instance_image']]\n",
    "outputs = clip.clip_forward(instance_texts, instance_images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_path = '/home/zhicai/poseVideo/lora-master/output_dog_Ti-Noclip_norm/lora_weight_e62_s10000.safetensors'\n",
    "# lora_path = '/home/zhicai/poseVideo/lora-master/output_dog_Ti-Noclip_norm/lora_weight_e62_s10000.safetensors'\n",
    "# lora_path = '../output_dog_cross+self_tR0.001_nR0.001/lora_weight_e12_s2000.safetensors'\n",
    "\n",
    "patch_pipe(\n",
    "    pipe,\n",
    "    lora_path,\n",
    "    patch_text=False,\n",
    "    patch_ti=True,\n",
    "    patch_unet=True,\n",
    "    filter_crossattn_str = 'cross+self'\n",
    ")\n",
    "\n",
    "prompts = 'photo of a <krk1> dog swimming in the pool' \n",
    "tune_lora_scale(pipe.unet, 0)\n",
    "torch.manual_seed(0)\n",
    "img = pipe([prompts] * 4, num_inference_steps=50, guidance_scale=7).images\n",
    "visualize_images(img,outpath=' ',nrow = 5, save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import re\n",
    "# '../output_dog_cross+self_tR0.001_nR0.001'\n",
    "_lora_path = '../output/output_dog_Ti-clip_norm_3e-5'\n",
    "prompts = ['photo of a <krk1> dog swimmking in the pool'] \n",
    "images = []\n",
    "bs = 4\n",
    "cnt = 0\n",
    "_files = os.listdir(_lora_path)\n",
    "pattern = r'lora_weight_e\\d+_s\\d{3,}.safetensors'\n",
    "files = [f for f in _files if re.match(pattern, f)]\n",
    "\n",
    "for i, path in enumerate(sorted(files, key = lambda x: int(re.match(r'.*e([0-9]+).*', x.split('/')[-1])[1]), reverse=False)):\n",
    "    if i % 10 ==0:\n",
    "        cnt +=1 \n",
    "        lora_path = os.path.join(_lora_path, path)\n",
    "        print(lora_path)\n",
    "        pipe_copy = copy.deepcopy(\n",
    "            pipe)\n",
    "        torch.manual_seed(0)\n",
    "        patch_pipe(\n",
    "            pipe_copy,\n",
    "            lora_path,\n",
    "            patch_text=False,\n",
    "            patch_ti=True,\n",
    "            patch_unet=True,\n",
    "            filter_crossattn_str = 'cross+self'\n",
    "        )\n",
    "        # pipe.unet\n",
    "        tune_lora_scale(pipe_copy.unet, 0.5)\n",
    "        # tune_lora_scale(pipe_copy.text_encoder, 1)\n",
    "        for prompt in prompts:\n",
    "            prompt = [prompt]*bs\n",
    "            img = pipe_copy(prompt = prompt, num_inference_steps=50, guidance_scale=6).images\n",
    "            images.extend(img)\n",
    "if len(images) > 0:\n",
    "    visualize_images(images,outpath='photo_of_krk1_norm_dog', nrow=4, show=False,save=True)\n",
    "else:\n",
    "    print('no images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import re\n",
    "# '../output_dog_cross+self_tR0.001_nR0.001'\n",
    "_lora_path = '../output_dog_cross+self_tR0.001_Scale-nR0.01'\n",
    "prompts = ['<krk> dog in a construction outfit','<krk> dog in times square'] \n",
    "images = []\n",
    "bs = 2\n",
    "cnt = 0\n",
    "_files = os.listdir(_lora_path)\n",
    "pattern = r'lora_weight_e\\d+_s\\d{4,}.safetensors'\n",
    "files = [f for f in _files if re.match(pattern, f)]\n",
    "\n",
    "for path in sorted(files, key = lambda x: int(re.match(r'.*e([0-9]+).*', x.split('/')[-1])[1]), reverse=True):\n",
    "    cnt +=1 \n",
    "    lora_path = os.path.join(_lora_path, path)\n",
    "    print(lora_path)\n",
    "    pipe_copy = copy.deepcopy(\n",
    "        pipe)\n",
    "    torch.manual_seed(0)\n",
    "    patch_pipe(\n",
    "        pipe_copy,\n",
    "        lora_path,\n",
    "        patch_text=False,\n",
    "        patch_ti=True,\n",
    "        patch_unet=True,\n",
    "        filter_crossattn_str = 'cross+self'\n",
    "    )\n",
    "    # pipe.unet\n",
    "    tune_lora_scale(pipe_copy.unet, 1)\n",
    "    # tune_lora_scale(pipe_copy.text_encoder, 1)\n",
    "    for prompt in prompts:\n",
    "        prompt = [prompt]*bs\n",
    "        img = pipe_copy(prompt = prompt, num_inference_steps=50, guidance_scale=6).images\n",
    "        images.extend(img)\n",
    "    if cnt >=3 :\n",
    "        break\n",
    "if len(images) > 0:\n",
    "    visualize_images(images,outpath='photo_of_krk_dog.jpg', nrow=4, save=False)\n",
    "else:\n",
    "    print('no images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 创建一个简单的神经网络模型\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(2, 4)\n",
    "        self.layer2 = nn.Linear(4, 3)\n",
    "        self.layer3 = nn.Linear(3, 1)\n",
    "\n",
    "        # 将第二层的参数设置为不需要梯度\n",
    "        for param in self.layer2.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "# 创建输入数据\n",
    "input_data = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "input_data2 = torch.tensor([[2.0, 2.0], [3.0, 4.0]])\n",
    "\n",
    "# 创建模型实例\n",
    "model = SimpleModel()\n",
    "\n",
    "\n",
    "# 进行前向传播\n",
    "model.zero_grad()\n",
    "output = model(input_data)\n",
    "output2 = model(input_data2)\n",
    "\n",
    "# 创建损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 计算损失并进行反向传播\n",
    "loss = criterion(output2, torch.tensor([[0.0], [1.0]]))\n",
    "loss.backward(retain_graph=True)\n",
    "\n",
    "# 打印第一层和第三层的参数的梯度\n",
    "print(\"Layer 1 gradients:\")\n",
    "print(model.layer1.weight.grad)\n",
    "print(model.layer1.bias.grad)\n",
    "\n",
    "print(\"\\nLayer 2 gradients (should be None):\")\n",
    "print(model.layer2.weight.grad)\n",
    "print(model.layer2.bias.grad)\n",
    "\n",
    "print(\"\\nLayer 3 gradients:\")\n",
    "print(model.layer3.weight.grad)\n",
    "print(model.layer3.bias.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import grad\n",
    "#             retain_graph=(i < len(loglikelihoods) - 1)\n",
    "\n",
    "model.zero_grad()\n",
    "output2 = model(input_data2)\n",
    "grad_out = grad((2*output2).mean(), model.layer2.parameters(), retain_graph=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(2, 4)\n",
    "        self.layer2 = nn.Linear(4, 3)\n",
    "        self.layer3 = nn.Linear(3, 1)\n",
    "\n",
    "        # 将第二层的参数设置为不需要梯度\n",
    "        for param in self.layer2.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "# 创建输入数据\n",
    "input_data = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "input_data2 = torch.tensor([[2.0, 2.0], [3.0, 4.0]])\n",
    "\n",
    "# 创建模型实例\n",
    "model = SimpleModel()\n",
    "model, criterion = accelerator.prepare(model, nn.MSELoss())\n",
    "input_data, input_data2 = accelerator.prepare(input_data, input_data2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行前向传播\n",
    "model.zero_grad()\n",
    "output = model(input_data)\n",
    "output2 = model(input_data2)\n",
    "\n",
    "# 计算损失并进行反向传播\n",
    "loss = criterion(output2, torch.tensor([[0.0], [1.0]]).to(accelerator.device))\n",
    "accelerator.backward(loss, retain_graph=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印第一层和第三层的参数的梯度\n",
    "print(\"Layer 1 gradients:\")\n",
    "print(accelerator.grad(model.layer1.weight))\n",
    "print(accelerator.grad(model.layer1.bias))\n",
    "\n",
    "print(\"\\nLayer 2 gradients (should be None):\")\n",
    "print(accelerator.grad(model.layer2.weight))\n",
    "print(accelerator.grad(model.layer2.bias))\n",
    "\n",
    "print(\"\\nLayer 3 gradients:\")\n",
    "print(accelerator.grad(model.layer3.weight))\n",
    "print(accelerator.grad(model.layer3.bias))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 10:32:42.798609: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 2 GPUs.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from accelerate.utils import reduce , broadcast\n",
    "\n",
    "class LoraInjectedLinear(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_features, out_features, bias=False, r=4, dropout_p=0.1, scale=1.0\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if r > min(in_features, out_features):\n",
    "            raise ValueError(\n",
    "                f\"LoRA rank {r} must be less or equal than {min(in_features, out_features)}\"\n",
    "            )\n",
    "        self.r = r\n",
    "        self.linear = nn.Linear(in_features, out_features, bias)\n",
    "        self.lora_down = nn.Linear(in_features, r, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.lora_up = nn.Linear(r, out_features, bias=False)\n",
    "        self.scale = scale\n",
    "        self.selector = nn.Identity()\n",
    "\n",
    "        nn.init.normal_(self.lora_down.weight, std=1 / r)\n",
    "        nn.init.zeros_(self.lora_up.weight)\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        return (\n",
    "            self.linear(input)\n",
    "            + self.dropout(self.lora_up(self.selector(self.lora_down(input))))\n",
    "            * self.scale\n",
    "        )\n",
    "\n",
    "    def realize_as_lora(self):\n",
    "        return self.lora_up.weight.data * self.scale, self.lora_down.weight.data\n",
    "   \n",
    "    def get_reg_loss(self,reg_vector = None):\n",
    "        if reg_vector is None:\n",
    "            if getattr(self, 'fisher'):\n",
    "                weight_reg = (self.lora_up.weight.pow(2) * self.fisher).sum()\n",
    "            else: \n",
    "                # L2 norm of the weight matrix\n",
    "                weight_reg = torch.norm(self.lora_up.weight, dim = [1], p = 2) + \\\n",
    "                         torch.norm(self.lora_down.weight, dim = [0], p = 2)\n",
    "            return weight_reg\n",
    "        else:\n",
    "            lora_project_vector = self.lora_up(self.lora_down(reg_vector))\n",
    "            return torch.norm(lora_project_vector, dim =[1,2], p = 2)\n",
    "        \n",
    "    def update_fisher(self):\n",
    "        # update fisher information of lora-up matrix\n",
    "        # TODO\n",
    "        if not getattr(self,'fisher'):\n",
    "            self._fisher_steps = 1\n",
    "            setattr(self,'fisher',torch.zeros_like(self.lora_up.weight))\n",
    "        else:\n",
    "            self._fisher_steps += 1\n",
    "            _a = self._fisher_steps\n",
    "            self.fisher = self.fisher*((_a-1)/_a) + self.lora_up.weight.grad.detach().pow(2)*(1/_a)\n",
    "\n",
    "    def set_selector_from_diag(self, diag: torch.Tensor):\n",
    "        # diag is a 1D tensor of size (r,)\n",
    "        assert diag.shape == (self.r,)\n",
    "        self.selector = nn.Linear(self.r, self.r, bias=False)\n",
    "        self.selector.weight.data = torch.diag(diag)\n",
    "        self.selector.weight.data = self.selector.weight.data.to(\n",
    "            self.lora_up.weight.device\n",
    "        ).to(self.lora_up.weight.dtype)\n",
    "\n",
    "def train():\n",
    "    model = LoraInjectedLinear(20,40,r=4)\n",
    "    accelerator = Accelerator()\n",
    "    model = accelerator.prepare(model)\n",
    "    ewc_prams = []\n",
    "    freeze_prams = []\n",
    "    for name, parameters in model.named_parameters():\n",
    "        if 'lora_up' in name:\n",
    "            ewc_prams.append(parameters)\n",
    "        else:\n",
    "            freeze_prams.append(parameters)\n",
    "    with open('log.txt','w') as f:\n",
    "    # for _ in range(10):\n",
    "        in_features = torch.randn(1, 3, 10, 20).to(accelerator.device)\n",
    "        out_features = model(in_features)\n",
    "        likelihood = out_features.mean()\n",
    "        accelerator.backward(likelihood, retain_graph=False)\n",
    "        model.update_fisher()\n",
    "        print(model.fisher)\n",
    "        f.write(f\"current process {accelerator.process_index}, fisher matrix {model.fisher}\")\n",
    "        reduce(model.fisher, reduction = 'mean')\n",
    "        accelerator.log(f\"current process {accelerator.process_index}, fisher matrix {model.fisher}\")\n",
    "        broadcast(model.fisher, from_prcocess = 0)\n",
    "        accelerator.log(f\"current process {accelerator.process_index}, fisher matrix {model.fisher}\")\n",
    "\n",
    "\n",
    "        # accelerator.backward(likelihood, retain_graph=False)\n",
    "notebook_launcher(train, num_processes=2, use_port=28700)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_3661474/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2355735933.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_3661474/2355735933.py'</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_3661474/\u001b[0m\u001b[1;33m2355735933.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_3661474/2355735933.py'\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'model'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_custom_objects',\n",
       " '_dataloaders',\n",
       " '_do_sync',\n",
       " '_get_devices',\n",
       " '_get_named_parameters',\n",
       " '_load_model_state_pre_hook',\n",
       " '_models',\n",
       " '_optimizers',\n",
       " '_prepare_deepspeed',\n",
       " '_prepare_fsdp',\n",
       " '_prepare_ipex',\n",
       " '_prepare_megatron_lm',\n",
       " '_prepare_one',\n",
       " '_save_model_state_pre_hook',\n",
       " '_schedulers',\n",
       " 'accumulate',\n",
       " 'autocast',\n",
       " 'backward',\n",
       " 'clear',\n",
       " 'clip_grad_norm_',\n",
       " 'clip_grad_value_',\n",
       " 'ddp_handler',\n",
       " 'device',\n",
       " 'device_placement',\n",
       " 'dispatch_batches',\n",
       " 'distributed_type',\n",
       " 'end_training',\n",
       " 'even_batches',\n",
       " 'fp8_recipe_handler',\n",
       " 'free_memory',\n",
       " 'gather',\n",
       " 'gather_for_metrics',\n",
       " 'get_state_dict',\n",
       " 'get_tracker',\n",
       " 'gradient_accumulation_steps',\n",
       " 'gradient_state',\n",
       " 'init_handler',\n",
       " 'init_trackers',\n",
       " 'is_last_process',\n",
       " 'is_local_main_process',\n",
       " 'is_main_process',\n",
       " 'join_uneven_inputs',\n",
       " 'load_state',\n",
       " 'local_main_process_first',\n",
       " 'local_process_index',\n",
       " 'log',\n",
       " 'log_with',\n",
       " 'logging_dir',\n",
       " 'main_process_first',\n",
       " 'mixed_precision',\n",
       " 'native_amp',\n",
       " 'no_sync',\n",
       " 'num_processes',\n",
       " 'on_last_process',\n",
       " 'on_local_main_process',\n",
       " 'on_local_process',\n",
       " 'on_main_process',\n",
       " 'on_process',\n",
       " 'optimizer_step_was_skipped',\n",
       " 'pad_across_processes',\n",
       " 'prepare',\n",
       " 'prepare_data_loader',\n",
       " 'prepare_model',\n",
       " 'prepare_optimizer',\n",
       " 'prepare_scheduler',\n",
       " 'print',\n",
       " 'process_index',\n",
       " 'project_configuration',\n",
       " 'project_dir',\n",
       " 'reduce',\n",
       " 'register_for_checkpointing',\n",
       " 'register_load_state_pre_hook',\n",
       " 'register_save_state_pre_hook',\n",
       " 'rng_types',\n",
       " 'save',\n",
       " 'save_iteration',\n",
       " 'save_state',\n",
       " 'scaler',\n",
       " 'scaler_handler',\n",
       " 'skip_first_batches',\n",
       " 'split_batches',\n",
       " 'state',\n",
       " 'step',\n",
       " 'step_scheduler_with_optimizer',\n",
       " 'sync_gradients',\n",
       " 'unscale_gradients',\n",
       " 'unwrap_model',\n",
       " 'use_distributed',\n",
       " 'use_fp16',\n",
       " 'wait_for_everyone']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(accelerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker ForkPoolWorker-140 initializing\n",
      "Worker ForkPoolWorker-140 executing task 0\n",
      "Worker ForkPoolWorker-141 initializing\n",
      "Worker ForkPoolWorker-141 executing task 2\n",
      "Worker ForkPoolWorker-141 executing task 3\n",
      "Worker ForkPoolWorker-140 executing task 1\n",
      "Worker ForkPoolWorker-142 initializing\n",
      "Worker ForkPoolWorker-142 executing task 4\n",
      "Worker ForkPoolWorker-143 initializing\n",
      "Worker ForkPoolWorker-143 executing task 6\n",
      "Worker ForkPoolWorker-142 executing task 5\n",
      "Worker ForkPoolWorker-143 executing task 7\n",
      "Worker ForkPoolWorker-144 initializing\n",
      "Worker ForkPoolWorker-144 executing task 8\n",
      "Worker ForkPoolWorker-145 initializing\n",
      "Worker ForkPoolWorker-144 executing task 9\n",
      "Results: [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "import random\n",
    "\n",
    "def init_worker():\n",
    "    print(f\"Worker {multiprocessing.current_process().name} initializing\")\n",
    "\n",
    "def worker_function(task_id):\n",
    "    print(f\"Worker {multiprocessing.current_process().name} executing task {task_id}\")\n",
    "    time.sleep(random.randint(4,5))\n",
    "    return task_id * 2\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_tasks = 10\n",
    "    processes = 2  # 使用默认工作进程数量\n",
    "\n",
    "    # 创建进程池并设置参数\n",
    "    with multiprocessing.Pool(processes=processes, initializer=init_worker, maxtasksperchild=1) as pool:\n",
    "        tasks = list(range(num_tasks))\n",
    "\n",
    "        # 调用 worker_function 并获取结果\n",
    "        results = pool.map(worker_function, tasks)\n",
    "\n",
    "    print(\"Results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker ForkPoolWorker-130 initializing\n",
      "Worker ForkPoolWorker-130 executing task 0\n",
      "Worker ForkPoolWorker-131 initializing\n",
      "Worker ForkPoolWorker-131 executing task 1\n",
      "Worker ForkPoolWorker-130 executing task 2\n",
      "Worker ForkPoolWorker-131 executing task 3\n",
      "Worker ForkPoolWorker-132 initializing\n",
      "Worker ForkPoolWorker-132 executing task 4\n",
      "Worker ForkPoolWorker-133 initializing\n",
      "Worker ForkPoolWorker-133 executing task 5\n",
      "Worker ForkPoolWorker-132 executing task 6\n",
      "Worker ForkPoolWorker-133 executing task 7\n",
      "Worker ForkPoolWorker-134 initializing\n",
      "Worker ForkPoolWorker-134 executing task 8\n",
      "Worker ForkPoolWorker-135 initializing\n",
      "Worker ForkPoolWorker-135 executing task 9\n",
      "Results: [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def worker_function(task_id):\n",
    "    print(f\"Worker {multiprocessing.current_process().name} executing task {task_id}\")\n",
    "    time.sleep(random.randint(1, 5))\n",
    "    return task_id * 2\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_tasks = 10\n",
    "    processes = 2\n",
    "\n",
    "    # 创建进程池\n",
    "    with multiprocessing.Pool(initializer=init_worker,processes=processes,maxtasksperchild=2) as pool:\n",
    "        tasks = list(range(num_tasks))\n",
    "        results = []\n",
    "\n",
    "        # 同步执行任务并获取结果\n",
    "        for task_id in tasks:\n",
    "            result = pool.apply(worker_function, args=(task_id,))\n",
    "            results.append(result)\n",
    "\n",
    "    print(\"Results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-30\n",
      "-400\n",
      "-600\n",
      "-196\n",
      "-66\n",
      "-191\n",
      "-147\n",
      "-26\n",
      "-89\n",
      "+604\n",
      "+311\n",
      "+69\n",
      "+216\n",
      "+63\n",
      "+254\n",
      "+93\n",
      "+29\n",
      "+201\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "num = []\n",
    "with open('../log.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        outs = re.search('(\\+|-)\\d+',line)[0]\n",
    "        if outs is not None:\n",
    "            print(outs)\n",
    "            # num.append(int(outs[0]))\n",
    "        else:\n",
    "            raise ValueError('No number found')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob \n",
    "import os\n",
    "ckpt_lists = glob.glob(os.path.dirname(os.getcwd()) + '/outputs/checkpoints/*/shareTI_text_0.01_ewc_0.01/decay_lr_5e-4_gas_4/lora_weight_s2000.safetensors')\n",
    "len(ckpt_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_lists = glob.glob(os.path.dirname(os.getcwd()) + '/outputs/checkpoints/*/shareTI_baseline/decay_lr_5e-4_gas_4/lora_weight_s2000.safetensors')\n",
    "len(ckpt_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import os\n",
    "ckpt_lists = glob.glob(os.path.dirname(os.getcwd()) + '/outputs/checkpoints/*/shareTI_text_0.01_freeze-down/decay_lr_5e-4_gas_4/lora_weight_s2000.safetensors')\n",
    "len(ckpt_lists)\n",
    "os.makedirs('/data/zhicai/code/Text-regularized-customization/outputs/sample/aaaa/shareTI_text_0.01_ewc_0.01/decay_lr_5e-4_gas_4/lora_weight_s1600',exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
