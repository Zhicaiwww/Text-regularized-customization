{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! load_ext autoreload\n",
    "! autoreload 2\n",
    "from diffusers import StableDiffusionPipeline, EulerAncestralDiscreteScheduler\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "from itertools import groupby\n",
    "from typing import Callable, Dict, List, Optional, Set, Tuple, Type, Union\n",
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from lora_diffusion import LoraInjectedConv2d, LoraInjectedLinear, patch_pipe, tune_lora_scale\n",
    "from lora_diffusion.lora import _find_modules, UNET_CROSSATTN_TARGET_REPLACE\n",
    "from visualization.vis_image import visualize_images\n",
    "\n",
    "os.environ[\"DISABLE_TELEMETRY\"] = 'YES'\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "device = torch.device(\"cuda:3\")\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16,local_files_only=True,revision='39593d5650112b4cc580433f6b0435385882d819').to(device)\n",
    "pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "prompt = \"style of <s1><s2>, baby lion\"\n",
    "torch.manual_seed(0)\n",
    "# image = pipe(prompt, num_inference_steps=50, guidance_scale=7).images[0]\n",
    "\n",
    "# image  # nice. diffusers are cool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reg_lora.modules import CLIPTiDataset, CLIPTiScoreCalculator\n",
    "from lora_diffusion.lora import patch_pipe\n",
    "lora_ckpt = '../outputs/checkpoints/output_dog_Ti-clip_Nonorm_3e-5/lora_weight_e6_s1000.safetensors'\n",
    "torch.manual_seed(0)\n",
    "\n",
    "patch_pipe(\n",
    "    pipe,\n",
    "    lora_ckpt,\n",
    "    patch_text=False,\n",
    "    patch_ti=True,\n",
    "    patch_unet=True,\n",
    "    filter_crossattn_str = 'cross+self'\n",
    ")\n",
    "\n",
    "data  = CLIPTiDataset(instance_data_root=\"../custom_data/data/dog\",\n",
    "                      placeholder_tokens=\"<krk1>\",\n",
    "                      class_token='dog'\n",
    "                      )\n",
    "clip = CLIPTiScoreCalculator(text_model = pipe.text_encoder.text_model,\n",
    "                             tokenizer = pipe.tokenizer,\n",
    "                             placeholder_tokens = \"<krk1>\",\n",
    "                             class_token_len = 1)\n",
    "data_loader = torch.utils.data.DataLoader(data, batch_size=2, shuffle=False, num_workers=1)\n",
    "clip_batch = next(iter(data_loader))\n",
    "instance_texts = clip_batch['text']\n",
    "instance_images = [image for image in clip_batch['np_instance_image']]\n",
    "outputs = clip.clip_forward(instance_texts, instance_images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_path = '/home/zhicai/poseVideo/lora-master/output_dog_Ti-Noclip_norm/lora_weight_e62_s10000.safetensors'\n",
    "# lora_path = '/home/zhicai/poseVideo/lora-master/output_dog_Ti-Noclip_norm/lora_weight_e62_s10000.safetensors'\n",
    "# lora_path = '../output_dog_cross+self_tR0.001_nR0.001/lora_weight_e12_s2000.safetensors'\n",
    "\n",
    "patch_pipe(\n",
    "    pipe,\n",
    "    lora_path,\n",
    "    patch_text=False,\n",
    "    patch_ti=True,\n",
    "    patch_unet=True,\n",
    "    filter_crossattn_str = 'cross+self'\n",
    ")\n",
    "\n",
    "prompts = 'photo of a <krk1> dog swimming in the pool' \n",
    "tune_lora_scale(pipe.unet, 0)\n",
    "torch.manual_seed(0)\n",
    "img = pipe([prompts] * 4, num_inference_steps=50, guidance_scale=7).images\n",
    "visualize_images(img,outpath=' ',nrow = 5, save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import re\n",
    "# '../output_dog_cross+self_tR0.001_nR0.001'\n",
    "_lora_path = '../output/output_dog_Ti-clip_norm_3e-5'\n",
    "prompts = ['photo of a <krk1> dog swimmking in the pool'] \n",
    "images = []\n",
    "bs = 4\n",
    "cnt = 0\n",
    "_files = os.listdir(_lora_path)\n",
    "pattern = r'lora_weight_e\\d+_s\\d{3,}.safetensors'\n",
    "files = [f for f in _files if re.match(pattern, f)]\n",
    "\n",
    "for i, path in enumerate(sorted(files, key = lambda x: int(re.match(r'.*e([0-9]+).*', x.split('/')[-1])[1]), reverse=False)):\n",
    "    if i % 10 ==0:\n",
    "        cnt +=1 \n",
    "        lora_path = os.path.join(_lora_path, path)\n",
    "        print(lora_path)\n",
    "        pipe_copy = copy.deepcopy(\n",
    "            pipe)\n",
    "        torch.manual_seed(0)\n",
    "        patch_pipe(\n",
    "            pipe_copy,\n",
    "            lora_path,\n",
    "            patch_text=False,\n",
    "            patch_ti=True,\n",
    "            patch_unet=True,\n",
    "            filter_crossattn_str = 'cross+self'\n",
    "        )\n",
    "        # pipe.unet\n",
    "        tune_lora_scale(pipe_copy.unet, 0.5)\n",
    "        # tune_lora_scale(pipe_copy.text_encoder, 1)\n",
    "        for prompt in prompts:\n",
    "            prompt = [prompt]*bs\n",
    "            img = pipe_copy(prompt = prompt, num_inference_steps=50, guidance_scale=6).images\n",
    "            images.extend(img)\n",
    "if len(images) > 0:\n",
    "    visualize_images(images,outpath='photo_of_krk1_norm_dog', nrow=4, show=False,save=True)\n",
    "else:\n",
    "    print('no images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import re\n",
    "# '../output_dog_cross+self_tR0.001_nR0.001'\n",
    "_lora_path = '../output_dog_cross+self_tR0.001_Scale-nR0.01'\n",
    "prompts = ['<krk> dog in a construction outfit','<krk> dog in times square'] \n",
    "images = []\n",
    "bs = 2\n",
    "cnt = 0\n",
    "_files = os.listdir(_lora_path)\n",
    "pattern = r'lora_weight_e\\d+_s\\d{4,}.safetensors'\n",
    "files = [f for f in _files if re.match(pattern, f)]\n",
    "\n",
    "for path in sorted(files, key = lambda x: int(re.match(r'.*e([0-9]+).*', x.split('/')[-1])[1]), reverse=True):\n",
    "    cnt +=1 \n",
    "    lora_path = os.path.join(_lora_path, path)\n",
    "    print(lora_path)\n",
    "    pipe_copy = copy.deepcopy(\n",
    "        pipe)\n",
    "    torch.manual_seed(0)\n",
    "    patch_pipe(\n",
    "        pipe_copy,\n",
    "        lora_path,\n",
    "        patch_text=False,\n",
    "        patch_ti=True,\n",
    "        patch_unet=True,\n",
    "        filter_crossattn_str = 'cross+self'\n",
    "    )\n",
    "    # pipe.unet\n",
    "    tune_lora_scale(pipe_copy.unet, 1)\n",
    "    # tune_lora_scale(pipe_copy.text_encoder, 1)\n",
    "    for prompt in prompts:\n",
    "        prompt = [prompt]*bs\n",
    "        img = pipe_copy(prompt = prompt, num_inference_steps=50, guidance_scale=6).images\n",
    "        images.extend(img)\n",
    "    if cnt >=3 :\n",
    "        break\n",
    "if len(images) > 0:\n",
    "    visualize_images(images,outpath='photo_of_krk_dog.jpg', nrow=4, save=False)\n",
    "else:\n",
    "    print('no images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 创建一个简单的神经网络模型\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(2, 4)\n",
    "        self.layer2 = nn.Linear(4, 3)\n",
    "        self.layer3 = nn.Linear(3, 1)\n",
    "\n",
    "        # 将第二层的参数设置为不需要梯度\n",
    "        for param in self.layer2.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "# 创建输入数据\n",
    "input_data = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "input_data2 = torch.tensor([[2.0, 2.0], [3.0, 4.0]])\n",
    "\n",
    "# 创建模型实例\n",
    "model = SimpleModel()\n",
    "\n",
    "\n",
    "# 进行前向传播\n",
    "model.zero_grad()\n",
    "output = model(input_data)\n",
    "output2 = model(input_data2)\n",
    "\n",
    "# 创建损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 计算损失并进行反向传播\n",
    "loss = criterion(output2, torch.tensor([[0.0], [1.0]]))\n",
    "loss.backward(retain_graph=True)\n",
    "\n",
    "# 打印第一层和第三层的参数的梯度\n",
    "print(\"Layer 1 gradients:\")\n",
    "print(model.layer1.weight.grad)\n",
    "print(model.layer1.bias.grad)\n",
    "\n",
    "print(\"\\nLayer 2 gradients (should be None):\")\n",
    "print(model.layer2.weight.grad)\n",
    "print(model.layer2.bias.grad)\n",
    "\n",
    "print(\"\\nLayer 3 gradients:\")\n",
    "print(model.layer3.weight.grad)\n",
    "print(model.layer3.bias.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import grad\n",
    "#             retain_graph=(i < len(loglikelihoods) - 1)\n",
    "\n",
    "model.zero_grad()\n",
    "output2 = model(input_data2)\n",
    "grad_out = grad((2*output2).mean(), model.layer2.parameters(), retain_graph=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(2, 4)\n",
    "        self.layer2 = nn.Linear(4, 3)\n",
    "        self.layer3 = nn.Linear(3, 1)\n",
    "\n",
    "        # 将第二层的参数设置为不需要梯度\n",
    "        for param in self.layer2.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "# 创建输入数据\n",
    "input_data = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "input_data2 = torch.tensor([[2.0, 2.0], [3.0, 4.0]])\n",
    "\n",
    "# 创建模型实例\n",
    "model = SimpleModel()\n",
    "model, criterion = accelerator.prepare(model, nn.MSELoss())\n",
    "input_data, input_data2 = accelerator.prepare(input_data, input_data2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行前向传播\n",
    "model.zero_grad()\n",
    "output = model(input_data)\n",
    "output2 = model(input_data2)\n",
    "\n",
    "# 计算损失并进行反向传播\n",
    "loss = criterion(output2, torch.tensor([[0.0], [1.0]]).to(accelerator.device))\n",
    "accelerator.backward(loss, retain_graph=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印第一层和第三层的参数的梯度\n",
    "print(\"Layer 1 gradients:\")\n",
    "print(accelerator.grad(model.layer1.weight))\n",
    "print(accelerator.grad(model.layer1.bias))\n",
    "\n",
    "print(\"\\nLayer 2 gradients (should be None):\")\n",
    "print(accelerator.grad(model.layer2.weight))\n",
    "print(accelerator.grad(model.layer2.bias))\n",
    "\n",
    "print(\"\\nLayer 3 gradients:\")\n",
    "print(accelerator.grad(model.layer3.weight))\n",
    "print(accelerator.grad(model.layer3.bias))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from accelerate.utils import reduce , broadcast\n",
    "\n",
    "class LoraInjectedLinear(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_features, out_features, bias=False, r=4, dropout_p=0.1, scale=1.0\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if r > min(in_features, out_features):\n",
    "            raise ValueError(\n",
    "                f\"LoRA rank {r} must be less or equal than {min(in_features, out_features)}\"\n",
    "            )\n",
    "        self.r = r\n",
    "        self.linear = nn.Linear(in_features, out_features, bias)\n",
    "        self.lora_down = nn.Linear(in_features, r, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.lora_up = nn.Linear(r, out_features, bias=False)\n",
    "        self.scale = scale\n",
    "        self.selector = nn.Identity()\n",
    "\n",
    "        nn.init.normal_(self.lora_down.weight, std=1 / r)\n",
    "        nn.init.zeros_(self.lora_up.weight)\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        return (\n",
    "            self.linear(input)\n",
    "            + self.dropout(self.lora_up(self.selector(self.lora_down(input))))\n",
    "            * self.scale\n",
    "        )\n",
    "\n",
    "    def realize_as_lora(self):\n",
    "        return self.lora_up.weight.data * self.scale, self.lora_down.weight.data\n",
    "   \n",
    "    def get_reg_loss(self,reg_vector = None):\n",
    "        if reg_vector is None:\n",
    "            if getattr(self, 'fisher'):\n",
    "                weight_reg = (self.lora_up.weight.pow(2) * self.fisher).sum()\n",
    "            else: \n",
    "                # L2 norm of the weight matrix\n",
    "                weight_reg = torch.norm(self.lora_up.weight, dim = [1], p = 2) + \\\n",
    "                         torch.norm(self.lora_down.weight, dim = [0], p = 2)\n",
    "            return weight_reg\n",
    "        else:\n",
    "            lora_project_vector = self.lora_up(self.lora_down(reg_vector))\n",
    "            return torch.norm(lora_project_vector, dim =[1,2], p = 2)\n",
    "        \n",
    "    def update_fisher(self):\n",
    "        # update fisher information of lora-up matrix\n",
    "        # TODO\n",
    "        if not getattr(self,'fisher'):\n",
    "            self._fisher_steps = 1\n",
    "            setattr(self,'fisher',torch.zeros_like(self.lora_up.weight))\n",
    "        else:\n",
    "            self._fisher_steps += 1\n",
    "            _a = self._fisher_steps\n",
    "            self.fisher = self.fisher*((_a-1)/_a) + self.lora_up.weight.grad.detach().pow(2)*(1/_a)\n",
    "\n",
    "    def set_selector_from_diag(self, diag: torch.Tensor):\n",
    "        # diag is a 1D tensor of size (r,)\n",
    "        assert diag.shape == (self.r,)\n",
    "        self.selector = nn.Linear(self.r, self.r, bias=False)\n",
    "        self.selector.weight.data = torch.diag(diag)\n",
    "        self.selector.weight.data = self.selector.weight.data.to(\n",
    "            self.lora_up.weight.device\n",
    "        ).to(self.lora_up.weight.dtype)\n",
    "\n",
    "def train():\n",
    "    model = LoraInjectedLinear(20,40,r=4)\n",
    "    accelerator = Accelerator()\n",
    "    model = accelerator.prepare(model)\n",
    "    ewc_prams = []\n",
    "    freeze_prams = []\n",
    "    for name, parameters in model.named_parameters():\n",
    "        if 'lora_up' in name:\n",
    "            ewc_prams.append(parameters)\n",
    "        else:\n",
    "            freeze_prams.append(parameters)\n",
    "    with open('log.txt','w') as f:\n",
    "    # for _ in range(10):\n",
    "        in_features = torch.randn(1, 3, 10, 20).to(accelerator.device)\n",
    "        out_features = model(in_features)\n",
    "        likelihood = out_features.mean()\n",
    "        accelerator.backward(likelihood, retain_graph=False)\n",
    "        model.update_fisher()\n",
    "        print(model.fisher)\n",
    "        f.write(f\"current process {accelerator.process_index}, fisher matrix {model.fisher}\")\n",
    "        reduce(model.fisher, reduction = 'mean')\n",
    "        accelerator.log(f\"current process {accelerator.process_index}, fisher matrix {model.fisher}\")\n",
    "        broadcast(model.fisher, from_prcocess = 0)\n",
    "        accelerator.log(f\"current process {accelerator.process_index}, fisher matrix {model.fisher}\")\n",
    "\n",
    "\n",
    "        # accelerator.backward(likelihood, retain_graph=False)\n",
    "notebook_launcher(train, num_processes=2, use_port=28700)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(accelerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "import random\n",
    "\n",
    "def init_worker():\n",
    "    print(f\"Worker {multiprocessing.current_process().name} initializing\")\n",
    "\n",
    "def worker_function(task_id):\n",
    "    print(f\"Worker {multiprocessing.current_process().name} executing task {task_id}\")\n",
    "    time.sleep(random.randint(4,5))\n",
    "    return task_id * 2\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_tasks = 10\n",
    "    processes = 2  # 使用默认工作进程数量\n",
    "\n",
    "    # 创建进程池并设置参数\n",
    "    with multiprocessing.Pool(processes=processes, initializer=init_worker, maxtasksperchild=1) as pool:\n",
    "        tasks = list(range(num_tasks))\n",
    "\n",
    "        # 调用 worker_function 并获取结果\n",
    "        results = pool.map(worker_function, tasks)\n",
    "\n",
    "    print(\"Results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def worker_function(task_id):\n",
    "    print(f\"Worker {multiprocessing.current_process().name} executing task {task_id}\")\n",
    "    time.sleep(random.randint(1, 5))\n",
    "    return task_id * 2\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_tasks = 10\n",
    "    processes = 2\n",
    "\n",
    "    # 创建进程池\n",
    "    with multiprocessing.Pool(initializer=init_worker,processes=processes,maxtasksperchild=2) as pool:\n",
    "        tasks = list(range(num_tasks))\n",
    "        results = []\n",
    "\n",
    "        # 同步执行任务并获取结果\n",
    "        for task_id in tasks:\n",
    "            result = pool.apply(worker_function, args=(task_id,))\n",
    "            results.append(result)\n",
    "\n",
    "    print(\"Results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "num = []\n",
    "with open('../log.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        outs = re.search('(\\+|-)\\d+',line)[0]\n",
    "        if outs is not None:\n",
    "            print(outs)\n",
    "            # num.append(int(outs[0]))\n",
    "        else:\n",
    "            raise ValueError('No number found')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import os\n",
    "ckpt_lists = glob.glob(os.path.dirname(os.getcwd()) + '/outputs/checkpoints/*/shareTI_text_0.01_ewc_0.01/decay_lr_5e-4_gas_4/lora_weight_s2000.safetensors')\n",
    "len(ckpt_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_lists = glob.glob(os.path.dirname(os.getcwd()) + '/outputs/checkpoints/*/shareTI_baseline/decay_lr_5e-4_gas_4/lora_weight_s2000.safetensors')\n",
    "len(ckpt_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import os\n",
    "ckpt_lists = glob.glob(os.path.dirname(os.getcwd()) + '/outputs/checkpoints/*/shareTI_text_0.01_freeze-down/decay_lr_5e-4_gas_4/lora_weight_s2000.safetensors')\n",
    "len(ckpt_lists)\n",
    "os.makedirs('/data/zhicai/code/Text-regularized-customization/outputs/sample/aaaa/shareTI_text_0.01_ewc_0.01/decay_lr_5e-4_gas_4/lora_weight_s1600',exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.clip import CLIPTokenizer\n",
    "import os\n",
    "os.environ['HTTP_PROXY'] = 'http://localhost:8890'\n",
    "os.environ['HTTPS_PROXY'] = 'http://localhost:8890'\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\n",
    "    'runwayml/stable-diffusion-v1-5',\n",
    "    subfolder=\"tokenizer\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [49406, 1929, 49407], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('dog')\n",
    "# tokenizer.convert_ids_to_tokens(42170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
