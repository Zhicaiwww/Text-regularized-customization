{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "import torch\n",
    "device = torch.device('cuda')\n",
    "from reg_lora.clip_ti_reg import  CLIPTiTextModel\n",
    "from transformers import CLIPTokenizer\n",
    "from safetensors.torch import safe_open\n",
    "from custom_datasets.utils import parse_templates_class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CLIPTokenizer.from_pretrained(\n",
    "    \"models/stable-diffusion-v1-5\",\n",
    "    subfolder=\"tokenizer\",\n",
    "    local_files_only=True,\n",
    ")\n",
    "clip_encoder = CLIPTiTextModel.from_pretrained(\n",
    "    \"models/stable-diffusion-v1-5\",\n",
    "    subfolder=\"text_encoder\",\n",
    "    local_files_only=True,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_shift(lora_ckpt, mode, superclass, additional_prompt=[]):\n",
    "\n",
    "    if len(additional_prompt) > 0:\n",
    "        data = [prompt.replace('[class]', superclass) for prompt in additional_prompt]\n",
    "    else:\n",
    "        data = [f\"photo of a {superclass}\"]\n",
    "    print(data)\n",
    "    input_ids = tokenizer(\n",
    "        data,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=tokenizer.model_max_length,\n",
    "    ).input_ids.to(device)\n",
    "\n",
    "    text_feature = clip_encoder(input_ids)[0].data.mean(0).t().half()\n",
    "\n",
    "    if mode in ['baseline', 'textReg']:\n",
    "        safeloras = safe_open(os.path.join(lora_ckpt, \"lora_weight_s900.safetensors\"), framework=\"pt\", device=\"cuda\")\n",
    "    elif mode in ['priorReal', 'priorGen']:\n",
    "        safeloras = safe_open(os.path.join(lora_ckpt, \"lora_weight_s700.safetensors\"), framework=\"pt\", device=\"cuda\")\n",
    "    lora_dict = {}\n",
    "    for key in safeloras.keys():\n",
    "        if \"unet\" in key:\n",
    "            lora_dict[key] = safeloras.get_tensor(key)\n",
    "\n",
    "    weight_dict, text_dict = {}, {}\n",
    "    for key, value in lora_dict.items():\n",
    "        if ':up' in key:\n",
    "            result_key = key.replace(':up', '')\n",
    "            weight_dict[result_key] = torch.matmul(value, lora_dict[key.replace(':up', ':down')])\n",
    "            text_dict[result_key] = torch.matmul(weight_dict[result_key], text_feature)\n",
    "    weight_shift = torch.norm(torch.cat(list(weight_dict.values())), p=2)\n",
    "    text_shift = torch.norm(torch.cat(list(text_dict.values())), p=2)\n",
    "    return weight_shift, text_shift\n",
    "\n",
    "def calculate_means(tuple_list):\n",
    "    sum_1 = 0\n",
    "    sum_2 = 0\n",
    "    for tup in tuple_list:\n",
    "        sum_1 += tup[0]\n",
    "        sum_2 += tup[1]\n",
    "    mean_1 = sum_1 / len(tuple_list)\n",
    "    mean_2 = sum_2 / len(tuple_list)\n",
    "    return mean_1, mean_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bird near the beach']\n",
      "['bird near the beach']\n",
      "['cat near the beach']\n",
      "['clock near the beach']\n",
      "['dog near the beach']\n",
      "['teddybear near the beach']\n",
      "['tortoise_plushy near the beach']\n",
      "['wooden_pot near the beach']\n",
      "Mode 'priorGen': weight_shift 7.76, |  text_shift 158.50, \n"
     ]
    }
   ],
   "source": [
    "log_dir = \"logs/log_ablation/image_reg/log_type/1_default\"\n",
    "\n",
    "SHIFT_DICT = {'baseline': [], 'priorReal': [], 'priorGen': [], 'textReg': []}\n",
    "for root, dirs, files in sorted(os.walk(log_dir)):\n",
    "    for dir in sorted(dirs):\n",
    "        if any(k in dir for k in ['baseline', 'priorReal', 'priorGen', 'textReg']):\n",
    "            mode = re.search(r'baseline|priorReal|priorGen|textReg', dir).group()\n",
    "            target_name  = root.split(\"/\")[-1]\n",
    "            superclass = parse_templates_class_name(target_name)[-1]\n",
    "            lora_ckpt = os.path.join(root, dir)\n",
    "            weight_shift, text_shift = calc_shift(lora_ckpt, mode, superclass, additional_prompt=['[class] near the beach'])\n",
    "            SHIFT_DICT[mode].append((weight_shift, text_shift))\n",
    "\n",
    "for k, v in SHIFT_DICT.items():\n",
    "    if len(v) > 0:\n",
    "        weight_shift, text_shift = calculate_means(v)\n",
    "        print(f\"Mode '{k}': weight_shift {weight_shift:.2f}, |  text_shift {text_shift:.2f}, \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
