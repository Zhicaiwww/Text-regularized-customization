{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import safetensors\n",
    "from build.lib.lora_diffusion import parse_safeloras\n",
    "ckpt = safetensors.safe_open('../exps/output_dog_0.01/step_900.safetensors', framework=\"pt\", device=\"cpu\")\n",
    "lora = parse_safeloras(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 15 files: 100%|██████████| 15/15 [00:00<00:00, 49152.00it/s]\n"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline, EulerAncestralDiscreteScheduler\n",
    "import torch\n",
    "import os\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "device = torch.device(\"cuda:6\")\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(\n",
    "    \"cuda:6\"\n",
    ")\n",
    "pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.4258, device='cuda:6', dtype=torch.float16, grad_fn=<CopyBackwards>) tensor(2.2305, device='cuda:6', dtype=torch.float16, grad_fn=<CopyBackwards>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(24.0156, device='cuda:6', dtype=torch.float16, grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lora_diffusion import parse_safeloras\n",
    "c_reg = pipe._encode_prompt(['photo of a dog'],device,1,False)\n",
    "ckpt = safetensors.safe_open('../exps/output_dog_0.1/step_900.safetensors', framework=\"pt\", device=\"cpu\")\n",
    "lora = parse_safeloras(ckpt)  \n",
    "up_weight_self = lora['unet'][0][10].to(device)\n",
    "down_weight_self = lora['unet'][0][11].to(device)\n",
    "up_weight = lora['unet'][0][12].to(device)\n",
    "down_weight = lora['unet'][0][13].to(device)\n",
    "lora_project_self = down_weight_self.transpose(0,1) @ up_weight_self.transpose(0,1)\n",
    "lora_project = down_weight.transpose(0,1) @ up_weight.transpose(0,1)\n",
    "lora_reside = c_reg @ lora_project\n",
    "print(torch.norm(lora_project),torch.norm(lora_project_self))\n",
    "torch.norm(lora_reside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 to_k\n",
      "7 to_v\n",
      "15 to_k\n",
      "16 to_v\n",
      "24 to_k\n",
      "25 to_v\n",
      "33 to_k\n",
      "34 to_v\n",
      "42 to_k\n",
      "43 to_v\n",
      "51 to_k\n",
      "52 to_v\n",
      "60 to_k\n",
      "61 to_v\n",
      "69 to_k\n",
      "70 to_v\n",
      "78 to_k\n",
      "79 to_v\n",
      "87 to_k\n",
      "88 to_v\n",
      "96 to_k\n",
      "97 to_v\n",
      "105 to_k\n",
      "106 to_v\n",
      "114 to_k\n",
      "115 to_v\n",
      "123 to_k\n",
      "124 to_v\n",
      "132 to_k\n",
      "133 to_v\n",
      "141 to_k\n",
      "142 to_v\n"
     ]
    }
   ],
   "source": [
    "from lora_diffusion.lora import _find_modules,DEFAULT_TARGET_REPLACE\n",
    "cnt = 0\n",
    "for target, name, module in _find_modules(pipe.unet, DEFAULT_TARGET_REPLACE):\n",
    "    if module.in_features == 768:\n",
    "        print(cnt, name)\n",
    "    cnt += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
