{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: load_ext\n",
      "zsh:1: command not found: autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f82b011db10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "! load_ext autoreload\n",
    "! autoreload 2\n",
    "from diffusers import StableDiffusionPipeline, EulerAncestralDiscreteScheduler\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "from itertools import groupby\n",
    "from typing import Callable, Dict, List, Optional, Set, Tuple, Type, Union\n",
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from lora_diffusion import LoraInjectedConv2d, LoraInjectedLinear, patch_pipe, tune_lora_scale\n",
    "from lora_diffusion.lora import _find_modules, UNET_CROSSATTN_TARGET_REPLACE\n",
    "from reg_lora.visual import visualize_images\n",
    "\n",
    "# os.environ[\"DISABLE_TELEMETRY\"] = 'YES'\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "device = torch.device(\"cuda:3\")\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16,local_files_only=True,revision='39593d5650112b4cc580433f6b0435385882d819').to(device)\n",
    "pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "prompt = \"style of <s1><s2>, baby lion\"\n",
    "torch.manual_seed(0)\n",
    "# image = pipe(prompt, num_inference_steps=50, guidance_scale=7).images[0]\n",
    "\n",
    "# image  # nice. diffusers are cool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_path = '/home/zhicai/poseVideo/lora-master/output_dog_Ti-Noclip_norm/lora_weight_e62_s10000.safetensors'\n",
    "# lora_path = '/home/zhicai/poseVideo/lora-master/output_dog_Ti-Noclip_norm/lora_weight_e62_s10000.safetensors'\n",
    "# lora_path = '../output_dog_cross+self_tR0.001_nR0.001/lora_weight_e12_s2000.safetensors'\n",
    "\n",
    "patch_pipe(\n",
    "    pipe,\n",
    "    lora_path,\n",
    "    patch_text=False,\n",
    "    patch_ti=True,\n",
    "    patch_unet=True,\n",
    "    filter_crossattn_str = 'cross+self'\n",
    ")\n",
    "\n",
    "prompts = 'photo of a <krk1> dog swimming in the pool' \n",
    "tune_lora_scale(pipe.unet, 0)\n",
    "torch.manual_seed(0)\n",
    "img = pipe([prompts] * 4, num_inference_steps=50, guidance_scale=7).images\n",
    "visualize_images(img,outpath=' ',nrow = 5, save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output/output_dog_Ti-clip_norm_3e-5/lora_weight_e1_s200.safetensors\n",
      "<krk1>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:11<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output/output_dog_Ti-clip_norm_3e-5/lora_weight_e13_s2200.safetensors\n",
      "<krk1>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:11<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output/output_dog_Ti-clip_norm_3e-5/lora_weight_e26_s4200.safetensors\n",
      "<krk1>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:11<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output/output_dog_Ti-clip_norm_3e-5/lora_weight_e38_s6200.safetensors\n",
      "<krk1>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:11<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output/output_dog_Ti-clip_norm_3e-5/lora_weight_e51_s8200.safetensors\n",
      "<krk1>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:11<00:00,  4.52it/s]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import glob\n",
    "import re\n",
    "# '../output_dog_cross+self_tR0.001_nR0.001'\n",
    "_lora_path = '../output/output_dog_Ti-clip_norm_3e-5'\n",
    "prompts = ['photo of a <krk1> dog swimmking in the pool'] \n",
    "images = []\n",
    "bs = 4\n",
    "cnt = 0\n",
    "_files = os.listdir(_lora_path)\n",
    "pattern = r'lora_weight_e\\d+_s\\d{3,}.safetensors'\n",
    "files = [f for f in _files if re.match(pattern, f)]\n",
    "\n",
    "for i, path in enumerate(sorted(files, key = lambda x: int(re.match(r'.*e([0-9]+).*', x.split('/')[-1])[1]), reverse=False)):\n",
    "    if i % 10 ==0:\n",
    "        cnt +=1 \n",
    "        lora_path = os.path.join(_lora_path, path)\n",
    "        print(lora_path)\n",
    "        pipe_copy = copy.deepcopy(\n",
    "            pipe)\n",
    "        torch.manual_seed(0)\n",
    "        patch_pipe(\n",
    "            pipe_copy,\n",
    "            lora_path,\n",
    "            patch_text=False,\n",
    "            patch_ti=True,\n",
    "            patch_unet=True,\n",
    "            filter_crossattn_str = 'cross+self'\n",
    "        )\n",
    "        # pipe.unet\n",
    "        tune_lora_scale(pipe_copy.unet, 0.5)\n",
    "        # tune_lora_scale(pipe_copy.text_encoder, 1)\n",
    "        for prompt in prompts:\n",
    "            prompt = [prompt]*bs\n",
    "            img = pipe_copy(prompt = prompt, num_inference_steps=50, guidance_scale=6).images\n",
    "            images.extend(img)\n",
    "if len(images) > 0:\n",
    "    visualize_images(images,outpath='photo_of_krk1_norm_dog', nrow=4, show=False,save=True)\n",
    "else:\n",
    "    print('no images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import re\n",
    "# '../output_dog_cross+self_tR0.001_nR0.001'\n",
    "_lora_path = '../output_dog_cross+self_tR0.001_Scale-nR0.01'\n",
    "prompts = ['<krk> dog in a construction outfit','<krk> dog in times square'] \n",
    "images = []\n",
    "bs = 2\n",
    "cnt = 0\n",
    "_files = os.listdir(_lora_path)\n",
    "pattern = r'lora_weight_e\\d+_s\\d{4,}.safetensors'\n",
    "files = [f for f in _files if re.match(pattern, f)]\n",
    "\n",
    "for path in sorted(files, key = lambda x: int(re.match(r'.*e([0-9]+).*', x.split('/')[-1])[1]), reverse=True):\n",
    "    cnt +=1 \n",
    "    lora_path = os.path.join(_lora_path, path)\n",
    "    print(lora_path)\n",
    "    pipe_copy = copy.deepcopy(\n",
    "        pipe)\n",
    "    torch.manual_seed(0)\n",
    "    patch_pipe(\n",
    "        pipe_copy,\n",
    "        lora_path,\n",
    "        patch_text=False,\n",
    "        patch_ti=True,\n",
    "        patch_unet=True,\n",
    "        filter_crossattn_str = 'cross+self'\n",
    "    )\n",
    "    # pipe.unet\n",
    "    tune_lora_scale(pipe_copy.unet, 1)\n",
    "    # tune_lora_scale(pipe_copy.text_encoder, 1)\n",
    "    for prompt in prompts:\n",
    "        prompt = [prompt]*bs\n",
    "        img = pipe_copy(prompt = prompt, num_inference_steps=50, guidance_scale=6).images\n",
    "        images.extend(img)\n",
    "    if cnt >=3 :\n",
    "        break\n",
    "if len(images) > 0:\n",
    "    visualize_images(images,outpath='photo_of_krk_dog.jpg', nrow=4, save=False)\n",
    "else:\n",
    "    print('no images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
